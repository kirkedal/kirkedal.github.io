{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"x86prime A few tools for our x86 subset, x86prime, known as just \"prime\" Prerequisites Install ocaml and opam. This installs the default compiler version for the system, which may not be recent enough. Upgrade this to version 4.07, Then use opam to install menhir and ocamlbuild. On debian based linux this is sudo apt install ocaml opam opam init -a On some systems, the default ocaml version is too old. Use \"ocaml --version\" to find which version you have. If you have something before 4.05.0, you need to upgrade. Latest version is 4.07.0. To upgrade do: opam switch 4.07.0 [at this point you may be asked to run eval 'opam config env' - do it] You may have to use \"opam switch create\" instead of just \"opam switch\" On some systems, this is not enough, and we recommend that you exit your shell, then restart it before proceeding While OCaml 4.05 works, it produces a lot of warnings. If you'd rather have a clean build process, upgrade to 4.07.0 as described above. opam install menhir ocamlbuild Building The script \"buildall.sh\" will build 4 tools: primify, a tool which translates real x86 assembler into prime assembler prasm, the assembler, a tool which encodes prime assembler into a format known as \"hex\" prun, a tool which reads hex files and runs them prerf, like prun, but collect performance statistics The tools will be linked from the \"bin\" subdirectory. ./buildall.sh If by accident you have built part of the program using an old version, you may get an error during build indicating a version problem with part of the project. If this happens, remove the \"_build\" subdirectory. And build again. Generating x86 assembler x86 assembler is in files with suffix \".s\" You can write one yourself. Or generate one from a program written in \"C\" using a C-compiler. gcc -S -Og -fno-optimize-sibling-calls my_program.c Translating x86 into prime (x86prime) The \"primify\" program will translate an x86 assembler source file into correspondingly named \".prime\" files. bin/primify my_program.s This results in a new file, \"my_program.prime\" Encoding into hex format The simulators cannot directly read the symbolic prime assembler. You need to assemble it into hex-format. Use bin/prasm my_program.prime This produces \"my_program.hex\", which can be inspected to learn how the prime program is encoded in numbers. It also produces \"my_program.sym\", which is a list of symbols. This is used by the simulator to allow you to pick which part of the code to execute. Running Programs are simulated by \"prun\" bin/prun my_program.hex my_start_function Here, the label \"my_start_function\" must have been defined by the original \".prime\" program. Without more options, the simulation is silent. To see what happens, add \"-show\" option Sit back, relax and watch the blinkenlights. Generating a tracefile A tracefile records all changes to memory and register made by your program. You request a tracefile by the \"-tracefile\" option: bin/prun my_program.s my_start_function -tracefile prog.trc The subdirectory \"examples\" includes an example C program (bubblesort.c) which can be used as introduction to the tools. It has 2 entry-points, \"run\" and \"run2\". If you use \"run\" it will silently input an integer from the keyboard. If running it seems to just hang, try providing a small number and press enter. If you use \"run2\", it will instead try to access any command line arguments. To pass command line arguments into the simulated program, just add them to the command line after all the other arguments. The bubblesort.c program illustrates how the program can access the additional arguments, see the \"run2\" function. Limitations to cross-assembling The translation from x86 to prime is not perfect. When gcc optimizes heavily (\"-O2, -O3\"), the code patterns generated will not be translated correctly. In most cases primify will stop with an exception. We believe \"-Og\" to be working reasonably well, so stick to that. Tail-call optimization will result in code, which cannot be correctly translated into \"prime\", worse: this currently goes undetected - to disable it use \"-fno-optimize-sibling-calls\" When gcc needs to use almost all registers in a function, translation will either fail or just be incorrect. Using combinations of signed and unsigned longs may not be handled correctly. Using constants which cannot be represented in 32-bit 2-complement form may not be handled correctly. Larger \"switch\" statements can not be translated In short, we advise you to check the translation result for correctness instead of blindly trusting it.","title":"Home"},{"location":"#x86prime","text":"A few tools for our x86 subset, x86prime, known as just \"prime\"","title":"x86prime"},{"location":"#prerequisites","text":"Install ocaml and opam. This installs the default compiler version for the system, which may not be recent enough. Upgrade this to version 4.07, Then use opam to install menhir and ocamlbuild. On debian based linux this is sudo apt install ocaml opam opam init -a On some systems, the default ocaml version is too old. Use \"ocaml --version\" to find which version you have. If you have something before 4.05.0, you need to upgrade. Latest version is 4.07.0. To upgrade do: opam switch 4.07.0 [at this point you may be asked to run eval 'opam config env' - do it] You may have to use \"opam switch create\" instead of just \"opam switch\" On some systems, this is not enough, and we recommend that you exit your shell, then restart it before proceeding While OCaml 4.05 works, it produces a lot of warnings. If you'd rather have a clean build process, upgrade to 4.07.0 as described above. opam install menhir ocamlbuild","title":"Prerequisites"},{"location":"#building","text":"The script \"buildall.sh\" will build 4 tools: primify, a tool which translates real x86 assembler into prime assembler prasm, the assembler, a tool which encodes prime assembler into a format known as \"hex\" prun, a tool which reads hex files and runs them prerf, like prun, but collect performance statistics The tools will be linked from the \"bin\" subdirectory. ./buildall.sh If by accident you have built part of the program using an old version, you may get an error during build indicating a version problem with part of the project. If this happens, remove the \"_build\" subdirectory. And build again.","title":"Building"},{"location":"#generating-x86-assembler","text":"x86 assembler is in files with suffix \".s\" You can write one yourself. Or generate one from a program written in \"C\" using a C-compiler. gcc -S -Og -fno-optimize-sibling-calls my_program.c","title":"Generating x86 assembler"},{"location":"#translating-x86-into-prime-x86prime","text":"The \"primify\" program will translate an x86 assembler source file into correspondingly named \".prime\" files. bin/primify my_program.s This results in a new file, \"my_program.prime\"","title":"Translating x86 into prime (x86prime)"},{"location":"#encoding-into-hex-format","text":"The simulators cannot directly read the symbolic prime assembler. You need to assemble it into hex-format. Use bin/prasm my_program.prime This produces \"my_program.hex\", which can be inspected to learn how the prime program is encoded in numbers. It also produces \"my_program.sym\", which is a list of symbols. This is used by the simulator to allow you to pick which part of the code to execute.","title":"Encoding into hex format"},{"location":"#running","text":"Programs are simulated by \"prun\" bin/prun my_program.hex my_start_function Here, the label \"my_start_function\" must have been defined by the original \".prime\" program. Without more options, the simulation is silent. To see what happens, add \"-show\" option Sit back, relax and watch the blinkenlights.","title":"Running"},{"location":"#generating-a-tracefile","text":"A tracefile records all changes to memory and register made by your program. You request a tracefile by the \"-tracefile\" option: bin/prun my_program.s my_start_function -tracefile prog.trc The subdirectory \"examples\" includes an example C program (bubblesort.c) which can be used as introduction to the tools. It has 2 entry-points, \"run\" and \"run2\". If you use \"run\" it will silently input an integer from the keyboard. If running it seems to just hang, try providing a small number and press enter. If you use \"run2\", it will instead try to access any command line arguments. To pass command line arguments into the simulated program, just add them to the command line after all the other arguments. The bubblesort.c program illustrates how the program can access the additional arguments, see the \"run2\" function.","title":"Generating a tracefile"},{"location":"#limitations-to-cross-assembling","text":"The translation from x86 to prime is not perfect. When gcc optimizes heavily (\"-O2, -O3\"), the code patterns generated will not be translated correctly. In most cases primify will stop with an exception. We believe \"-Og\" to be working reasonably well, so stick to that. Tail-call optimization will result in code, which cannot be correctly translated into \"prime\", worse: this currently goes undetected - to disable it use \"-fno-optimize-sibling-calls\" When gcc needs to use almost all registers in a function, translation will either fail or just be incorrect. Using combinations of signed and unsigned longs may not be handled correctly. Using constants which cannot be represented in 32-bit 2-complement form may not be handled correctly. Larger \"switch\" statements can not be translated In short, we advise you to check the translation result for correctness instead of blindly trusting it.","title":"Limitations to cross-assembling"},{"location":"afviklingsplot/","text":"Afviklings Plot af Finn Schiermer Andersen, DIKU, 2019 Denne lille note introducerer afviklingsplot. Et afviklingsplot er en idealiseret illustration af hvordan en mikroarkitektur afvikler en str\u00f8m af instruktioner. Men det er ogs\u00e5 et redskab som kan bruges til at bestemme en mikroarkitekturs ydeevne for en str\u00f8m af instruktioner. Ide Under afvikling af hver instruktion p\u00e5 en given mikroarkitektur gennemg\u00e5r instruktionen forskellige faser. Et afviklingsplot angiver tidspunktet for hver v\u00e6sentlig fase en instruktion genneml\u00f8ber. Instruktionsstr\u00f8mmen angives yderst til venstre, oppefra og ned. Tiden angives i clock-perioder fra venstre mod h\u00f8jre. Her er for eksempel afviklingen af 4 instruktioner p\u00e5 en enkelt-cyklus (single cycle) mikroarkitektur 0123 movq (r10),r11 X addq $100,r11 X movq r1,(r10) X addq $1,r10 X Her er kun en enkelt fase, kaldet X for eXecute, da alle instruktioner kan udf\u00f8res p\u00e5 en enkelt clock-periode. Vi har alts\u00e5 den sekventielle model, som den vi forst\u00e5r n\u00e5r vi l\u00e6ser et assembler program; alts\u00e5 f\u00f8rst indl\u00e6ser vi noget fra hukommelsen, derefter ligger vi en v\u00e6di til dette, hvorefter vi skriver det tilbage til hukommelsen. Hvis vi \u00f8nsker at finde denne arkitekturs ydeevne, kan man alts\u00e5 g\u00f8re dette ved at t\u00e6lle antallet af instruktioner. Pipeline faser og ressourcer En instruktion gennemg\u00e5r nogle faser n\u00e5r den afvikles. Nogle faser er generiske; nogle afh\u00e6nger af instruktionen. Faserne genneml\u00f8bes i r\u00e6kkef\u00f8lge bestemt af instruktionstype og mikroarkitektur. Betragt for eksempel en afviklingen p\u00e5 en simpel pipeline, typisk for de f\u00f8rste RISC maskiner konstrueret i 80'erne. Her er der fem faser: FDXMW (Fetch, Decode, eXecute, Memory, Writeback). Alle instruktioner passerer gennem de samme fem trin. Her ses nogle begr\u00e6nsninger for en 5-trins pipeline: alle instruktioner: FDXMW ressourcer: F:1, D:1, X:1, M:1, W:1 Bem\u00e6rk at det er en voldsom forenkling at udtrykke begr\u00e6nsningen for instruktionshentning i et antal instruktioner. For en maskine med instruktioner af forskellig l\u00e6ngde er bindingen mere korrekt udtrykt som et antal bytes. F\u00f8rst i forbindelse med afkodning er det klart, hvor en instruktion begynder og slutter. Den lille detalje vil vi se bortfra. Her er et afviklingsplot: 01234567 movq (r10),r11 FDXMW addq $100,r12 FDXMW movq r13,(r10) FDXMW addq $1,r10 FDXMW Men hov! Hvorfor kunne det ikke v\u00e6re: 01234567 movq (r10),r11 FDXMW addq $100,r12 FDXMW movq r13,(r10) FDXMW addq $8,r10 FDXMW Vi har m\u00e5ske lidt sv\u00e6rt ved at se, hvordan en maskine overhovedet skulle kunne konstrueres s\u00e5ledes at ovenst\u00e5ende afviklingsr\u00e6kkef\u00f8lge kunne finde sted. Vi indf\u00f8rer derfor en begr\u00e6nsning mere: Hver fase gennemf\u00f8res i instruktions-r\u00e6kkef\u00f8lge. inorder(F,D,X,M,W) Data afh\u00e6ngigheder Instruktioner bruger en eller flere clock-perioder til at producere et resultat. Det kaldes instruktionens latenstid. Latenstiden er den tid der g\u00e5r fra instruktionen modtager/fremfinder sin sidste indg\u00e5ende operand og til en efterf\u00f8lgende instruktion som afh\u00e6nger af resultatet kan begynde sin beregning. Man planl\u00e6gger normalt en mikroarkitektur s\u00e5ledes at de grundl\u00e6ggende aritmetisk og logiske instruktioner har en latenstid p\u00e5 en enkelt clock periode. Andre instruktioner kan s\u00e5 f\u00e5 l\u00e6ngere latenstid, fordi de udf\u00f8rer et mere kompliceret stykke arbejde. For eksempel er multiplikation mere kompliceret end addition og har derfor en latenstid p\u00e5 3-4 clock perioder. Tilgang til lageret er ogs\u00e5 mere kompliceret og tager l\u00e6ngere tid end en enkelt clock periode. Ex: 5-trins pipeline, data forwarding alle instruktioner: FDXMW dataafh\u00e6ngigheder: simpel aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 multiplikation a op b: X.time = max(a.time, b.time); b.time = X.time + 4 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 1 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 1 inorder(F,D,X,M,W) resourcer pr clk: F:1, D:1, X:1, M:1, W:1 Giver f\u00f8lgende afvikling: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDXMW X.time = r11.time - Forsinket X, STALL i D, r11.time = 5 movq r11,(r10) FFDXMW resA - Forsinket D, STALL i F, X.time = r10.time, S.time = r11.time addq $8,r10 FDXMW resA - forsinket F, r10.time = 7 Bem\u00e6rk hvorledes instruktion nr. 2 bliver forsinket en clock periode i sin D-fase, fordi den afh\u00e6nger af r11 som bliver produceret af den forudg\u00e5ende instruktion der har en latenstid p\u00e5 2 clock-perioder. Superskalar mikroarkitektur I jagten efter h\u00f8jere ydeevne kan man finde p\u00e5 at skrue op for ressourcerne. Hvis der er mere end en instruktion der udf\u00f8rer sin X-fase samtidigt, taler man om en superskalar maskine. En simpel 2-vejs superskalar kan h\u00e5ndtere 2 instruktioner samtidigt i faserne F,D,X og W, men kun 1 instruktion samtidigt i fase M. Det er motiveret af at fase M er dyrere end de andre. Til geng\u00e6ld vil man knytte forskellige faser til forskellige klasser af instruktioner, s\u00e5ledes at ikke alle har en fase M. Man kan ogs\u00e5 undg\u00e5 en fase W for instruktioner der ikke skriver til et resultat register simpel aritmetik: FDXW movq (a),b: FDXMW movq b,(a): FDXM dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 1 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 1 inorder(F,D,X,M,W) resourcer pr clk: F:2, D:2, X:2, M:1, W:2 Giver os f\u00f8lgende afvikling: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDDXW X.time = r11.time - Forsinket X, Gentag D, r11.time = 5 movq r11,(r10) FDDXM resB - Forsinket D, Gentag F, X.time = r10.time, M.time = r11.time addq $8,r10 FFFDXW resB - Gentag F, r10.time = 7 Anonyme faser Det er lidt tr\u00e6ls, hvis man skal redeg\u00f8re separat for hver enkelt fase en instruktion genneml\u00f8ber i en moderne mikroarkitektur. Det skyldes at moderne mikroarkitekturer afvikler instruktioner i mange forskellige faser. L\u00e6ngere pipelines I moderne CMOS er det ikke realistisk at lave et cache-opslag p\u00e5 en enkelt cyklus. Typisk bruges tre cykler, fuldt pipelinet. Oftest er det heller ikke muligt at fuldt afkode en instruktion p\u00e5 en enkelt cyklus. Vi kunne navngive hver enkelt af de ekstra faser der kr\u00e6ves og opskrive regler for hver af dem. Vi v\u00e6lger en simplere notation: N\u00e5r vi opskriver faserne for en instruktionsklasse kan vi tilf\u00f8je anonyme faser som er p\u00e5kr\u00e6vet med \"-\" og angive hvor mange instuktioner der kan befinde sig i \"mellemrummet\" mellem to navngivne faser. Man kan v\u00e6lge at betragte tidligere beskrivelser af begr\u00e6nsinger som specialtilf\u00e6lde, hvor ingen instruktioner m\u00e5 v\u00e6re i anonyme faser, dvs: F-D: 0, D-X: 0, X-M: 0, M-W: 0. Her betyder s\u00e5leds \"F-D: 0\" at der ingen instruktioner m\u00e5 v\u00e6re, som har gennemf\u00f8rt fase F, men ikke p\u00e5begyndt D. Med andre ord: Fase D skal f\u00f8lge direkte efter fase F i afviklingsplottet For eksempel: resC: max pr clk: F-D: 4, D-X: 2, M-W: 2 Angiver 4 ekstra instruktioner mellem F og D, 2 ekstra mellem D og X og to ekstra mellem M og W. S\u00e5 vi i alt har: aritmetik: F--D-XW movq (a),b: F--D-XM--W movq b,(a): F--D-XM dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 3 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 3 inorder(F,D,X,M,W) resB: max pr clk: F:2, D:2, X:2, M:1, W:2 resC: max pr clk: F-D: 4, D-X: 2, M-W: 2 Hvilket giver f\u00f8lgende afvikling 012345678901234567 movq (r10),r11 F--D-XM--W r11.time = 9 addq $100,r11 F--D-----XW X.time = r11.time - Forsinket X, r11.time = 10 movq r11,(r10) F--D----XM X.time = r10.time, M.time = r11.time addq $8,r10 F--DDDDD-XW r10.time = 11 movq (r10),r11 F--DDDD--XM--W X.time = r10.time, r11.time = 15 addq $100,r11 F------D-----XW X.time = r11.time - Forsinket X, r11.time = 16 movq r11,(r10) F-----DD----XM X.time = r10.time, M.time = r11.time addq $8,r10 F------DDDDD-XW r10.time = 17 Vores specifikation kan kr\u00e6ve anonyme faser, f.eks. 2 mellem F og D som ovenfor, men vi kan ogs\u00e5 inds\u00e6tte yderligere anonyme faser i afviklingsplottet for at f\u00e5 afviklingen til at overholde andre begr\u00e6nsninger. Abstraktion Anonyme faser g\u00f8r det nemmere at se bort fra ting der ikke har interesse. For eksempel kan vi udelade afkodningstrinnet fra vores beskrivelse, men f\u00e5 samme afvikling: aritmetik: F----XW movq (a),b: F----XM--W movq b,(a): F----XM dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 3 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 3 inorder(F,X,M,W) resB: max pr clk: F:2, X:2, M:1, W:2 resC: max pr clk: F-X: 8, M-W: 2 Hvilket giver den samme afvikling, blot er 'D' ikke n\u00e6vnt. 012345678901234567 movq (r10),r11 F----XM--W r11.time = 9 addq $100,r11 F--------XW X.time = r11.time - Forsinket X, r11.time = 10 movq r11,(r10) F-------XM X.time = r10.time, M.time = r11.time addq $8,r10 F--------XW r10.time = 11 movq (r10),r11 F--------XM--W X.time = r10.time, r11.time = 15 addq $100,r11 F------------XW X.time = r11.time - Forsinket X, r11.time = 16 movq r11,(r10) F-----------XM X.time = r10.time, M.time = r11.time addq $8,r10 F------------XW r10.time = 17 Bem\u00e6rk i\u00f8vrigt at selvom denne maskine kan h\u00e5ndtere 2 instruktioner per clk, s\u00e5 opn\u00e5r den i ovenst\u00e5ende eksempel 8/11 IPC, dvs mindre end 1 instruktion per clk. K\u00f8er TBD Cache-miss TBD Out-of-order Faser i program-r\u00e6kkef\u00f8lge - eller ej Man kunne jo forestille sig: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDDXW X.time = r11.time - Forsinket X, Gentag D, r11.time = 5 movq r9,(r14) FDXM X.time = r14.time, M.time = r9.time ---- BEM\u00c6RK! addq $1,r10 FFDXXW resB - Gentag F, r10.time = 5 (eller 6) Bem\u00e6rk at instruktion nummer 3 her f\u00e5r sin X-fase en clock periode tidligere end instruktionen f\u00f8r. P\u00e5 en m\u00e5de overhaler instruktion nummer 3 alts\u00e5 instruktion nummer 2. Men det tillader vores inorder() erkl\u00e6ring ikke og giver os i stedet: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDDXW X.time = r11.time - Forsinket X, Gentag D, r11.time = 5 movq r9,(r14) FDDXM inorder(X) - Forsinket X, vent i D, X.time = r14.time, M.time = r9.time addq $1,r10 FFFDXW resB - Gentag F, r10.time = 7 Vi kan ane at der findes mere ydeevne i form af mere parallelisme i udf\u00f8relsen, hvis vi blot kan afvige fra inorder-kravet i en eller flere faser. Det har man gjort for \"special cases\" i mange maskiner gennem \u00e5rene, men de sidste 20 \u00e5r er der etableret en mere generel \"standard model\" for out-of-order maskiner Standardmodellen for out-of-order mikroarkitektur Inorder og out-of-order I denne model passerer instruktioner f\u00f8rst i programr\u00e6kkef\u00f8lge gennem en pipeline hvor de ender i en skeduleringsenhed (scheduler). Derfra kan de udf\u00f8res uden at overholde programr\u00e6kkef\u00f8lgen. Efter udf\u00f8rsel placeres resultaterne i en form for k\u00f8. Resultaterne udtages fra denne k\u00f8 og fuldf\u00f8res i programr\u00e6kkef\u00f8lge. Det g\u00e6lder s\u00e5vel for skrivninger til registre, som for skrivninger til lageret. Vi kan beskrive det ved f\u00f8lgende faser der er f\u00e6lles for alle instruktioner: F: Start p\u00e5 instruktionshentning Q: Ankomst til scheduler * C: Fuldf\u00f8relse Og vi benytter lejligheden til at fjerne W trinnet fra beskrivelsen. Lagerreferencer I de hidtil beskrevne maskiner bruger b\u00e5de lagerreferencer og aritmetiske instruktioner fasen X . Det afspejler at man i simple maskiner foretager adresseberegning med den samme hardware som man bruger til aritmetiske instruktioner. I standardmodellen har man i stedet en dedikeret fase til adresseberegning, kaldet A . Denne skelnen mellem A og X g\u00f8r at man kan begr\u00e6nse A til at forekomme i instruktionsr\u00e6kkef\u00f8lge, mens de andre beregninger ikke har den begr\u00e6nsning. Instruktioner der skriver til lageret har et v\u00e6sentlig mere kompliceret forl\u00f8b i en out-of-order maskine sammenlignet med en inorder maskine. Disse instruktioner m\u00e5 ikke opdatere lageret f\u00f8r C , s\u00e5 i stedet placeres skrivningerne i en skrive-k\u00f8. Skrive-k\u00f8en indeholder adresse og data som kan bruges til at udf\u00f8re skrivningen senere, efter C . Instruktioner indf\u00f8jes i skrivek\u00f8en umiddelbart efter A . Da A er en fase der udf\u00f8res i instruktionsr\u00e6kkef\u00f8lge, kan efterf\u00f8lgende instruktioner der l\u00e6ser fra lageret sammenligne deres adresse med udest\u00e5ende skrivninger i skrive-k\u00f8en, og hvis adressen matcher kan den tilsvarende v\u00e6rdi hentes fra skrive-k\u00f8en. Instruktioner der skriver til lageret kan (skal) inds\u00e6tte deres adresse i skrive-k\u00f8en selvom den v\u00e6rdi der skal skrives endnu ikke er beregnet. Det tidspunkt hvor v\u00e6rdien kopieres til skrive-k\u00f8en markeres V . En lille out-of-order model Her er en model af en lille out-of-order maskine aritmetik: F----QXC movq (a),b: F----QAM--C movq b,(a): F----QAMVC dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: A.time = a.time; M.time = MEM[a].time; b.time = M.time + 3 movq b,(a): A.time = a.time, V.time = b.time; MEM[a].time = V.time + 1 inorder(F,Q,C,A) outoforder(X,M) resB: max pr clk: F:2, Q:2, X:2, A:1, M:1, V:1, C:2 resC: max pr clk: F-Q: 8, M-W: 2, Q-C: 32 resD: unbounded: Q-X, Q-A, A-M, M-V, V-C, M-C Bem\u00e6rk at udover at faserne X og M nu er erkl\u00e6ret out-of-order, s\u00e5 er der indsat en begr\u00e6nsning p\u00e5 32 instruktioner fra Q til C. Det vil sige vi tillader 32 instruktioner at v\u00e6re i forskellige faser mellem Q og C. Dette kaldes skeduleringsvinduet. Jo st\u00f8rre det er, jo flere instruktioner kan maskinen \"se fremad\" i instruktionsstr\u00f8mmen. Bem\u00e6rk ogs\u00e5 at til forskel fra alle de tidligere maskiner er der ikke l\u00e6ngere noget krav om X skal f\u00f8lge i en bestemt afstand efter Q, eller at C skal f\u00f8lge i en bestemt afstand efter X eller M. Disse begr\u00e6nsninger ville give f\u00f8lgende udf\u00f8relse 012345678901234567 movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 movq (r10),r11 F----QAM---C X.time = r10.time, r11.time = 12 addq $100,r11 F----Q----XC X.time = r11.time, r11.time = 13 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 10 Med en gennemsnitlig ydeevne p\u00e5 2 IPC. Kontrol afh\u00e6ngigheder Modellering Vi modellerer effekten af hop, kald og retur ved at forsinke 'F'. For kald og retur skelner vi mellem korrekte og fejlagtige forudsigelser. For betingede hop skelner vi tillige mellem om hoppet tages eller ej. Vi udtrykker effekten ved tildelinger til en ny tidsvariabel: NextF.time Og for enhver instruktion g\u00e6lder altid at F.time = NextF.time Vi tilf\u00f8jer en ny fase, B , specifik for betingede hop, kald og retur. B svarer til X for de aritmetiske instruktioner. B angiver det tidspunkt, hvor vi afg\u00f8r om forudsigelser af instruktionen var korrekt eller ej. Vi tillader at B indtr\u00e6ffer out-of-order i forhold til andre typer instruktioner, men kr\u00e6ver det sker in-order i forhold til andre hop, kald eller retur. call a,b: F----QBC ret a: F----QBC cbcc a,b,x: F----QBC inorder(B) Her er nogle mulige regler for en out-of-order maskine som beskrevet ovenfor Instruktion Taget Forudsagt Effekt Call ja ja NextF.time = F.time + 2 Ret ja ja NextF.time = F.time + 2 ja nej NextF.time = B.time + 1 CBcc nej ja - (ingen) nej nej NextF.time = B.time + 1 ja ja NextF.time = F.time + 2 ja nej NextF.time = F.time + 2 Herunder ses to genneml\u00f8b af en indre l\u00f8kke, hvor hop forudsiges korrekt. 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbl r10,r12,loop F----QB----C NextF.time = 4 (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C r11.time = 14 addq $100,r11 F----Q----XC r11.time = 15 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 12 cbl r10,r12,loop F----QB----C Ydeevne: 5/4 IPC P\u00e5 grund af omkostningen ved hop vil en overs\u00e6tter ofte rulle en l\u00f8kke-krop ud en eller flere gange. Herunder ses effekten af en enkelt udrulning 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbgt r10,r12,exit F----QB----C forudsagt korrekt ikke taget movq (r10),r11 F----QAM---C r11.time = 13 addq $100,r11 F----Q----XC r11.time = 14 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 11 cbl r10,r12,loop F----QB----C NextF.time = 6 (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C r11.time = 16 Ydeevne: 10/6 IPC En anden teknik til at skjule omkostningen ved tagne hop er at man dimensionerer forenden af mikroarkitektur (F til Q) lidt st\u00f8rre end resten. Her er for eksempel et afviklingsplot for den ikke udrullede l\u00f8kke p\u00e5 en maskine der kan h\u00e5ndtere 3 instruktioner samtidigt i F til Q: 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----Q-AM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbl r10,r12,loop F----Q-B----C NextF.time = 3 (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C r11.time = 14 addq $100,r11 F----Q----XC r11.time = 15 movq r11,(r10) F----Q-AM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 12 cbl r10,r12,loop F----Q-B----C Ydeevne: 5/3 IPC Her ses effekten af en forkert forudsigelse: 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbl r10,r12,loop F----QB----C NextF.time = 9 (forudsagt forkert) loop: movq (r10),r11 F----QAM--C r11.time = 14 addq $100,r11 F----Q----XC r11.time = 15 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 12 Ydeevne 5/9 IPC Jo l\u00e6ngere pipeline, jo st\u00f8rre omkostning ved forkerte forudsigelser. spekulativ udf\u00f8relse Det kan ske at B fasen indtr\u00e6ffer meget sent i forhold til udf\u00f8relsen af andre instruktioner. Betragt for eksempel nedenst\u00e5ende stump kode long v = tab[j]; if (v key) { *ptr = *ptr + 1; // found it! } Oversat til x86prime kan det blive til f\u00f8lgende programstump: movq (r10,r11,8),r12 cble r12,r13,.endif movq (r15),r14 addq $1,r14 movq r14,(r15) .endif: og lad os antage at variablen 'tab' befinder sig i L2-cache, mens omr\u00e5det udpeget af variablen 'ptr' er i L1-cache. Lad os antage at L2-cache tilgang koster 10 cykler (oveni L1-tilgang). 01234567890123456789012 movq (r10,r11,8),r12 F----QAM------------C cble r12,r13,else F----Q--------------BC movq (r15),r14 F----QAM------------C addq $1,r14 F----Q----X----------C movq r14,(r15) F----QAM--V---------C Det betingede hop afh\u00e6nger af en instruktion der er n\u00f8d til at hente en v\u00e6rdi i L2 og bliver s\u00e5ledes forsinket s\u00e5 det f\u00f8rst kan afg\u00f8res i cyklus 20. Hoppet er forudsagt \"ikke taget\" og f\u00f8r det afg\u00f8res kan de n\u00e6ste tre instruktioner l\u00e6se fra L1-cachen, beregne en ny v\u00e6rdi og l\u00e6gge den i k\u00f8 til skrivning til L1. Det g\u00e5r selvsagt ikke an faktisk at opdatere L1, f\u00f8r vi ved om hoppet er forudsagt korrekt, men alle \u00f8vrige aktiviteter kan gennemf\u00f8res. De instruktioner som udf\u00f8res tidligere end et eller flere hop, kald eller retur, som de egentlig afh\u00e6nger af, siges at v\u00e6re spekulativt udf\u00f8rt. Spekulativ udf\u00f8relse fjerner en v\u00e6sentlig begr\u00e6nsning p\u00e5 hvor meget arbejde der kan udf\u00f8res parallelt.","title":"Afviklingsplot"},{"location":"afviklingsplot/#afviklings-plot","text":"af Finn Schiermer Andersen, DIKU, 2019 Denne lille note introducerer afviklingsplot. Et afviklingsplot er en idealiseret illustration af hvordan en mikroarkitektur afvikler en str\u00f8m af instruktioner. Men det er ogs\u00e5 et redskab som kan bruges til at bestemme en mikroarkitekturs ydeevne for en str\u00f8m af instruktioner.","title":"Afviklings Plot"},{"location":"afviklingsplot/#ide","text":"Under afvikling af hver instruktion p\u00e5 en given mikroarkitektur gennemg\u00e5r instruktionen forskellige faser. Et afviklingsplot angiver tidspunktet for hver v\u00e6sentlig fase en instruktion genneml\u00f8ber. Instruktionsstr\u00f8mmen angives yderst til venstre, oppefra og ned. Tiden angives i clock-perioder fra venstre mod h\u00f8jre. Her er for eksempel afviklingen af 4 instruktioner p\u00e5 en enkelt-cyklus (single cycle) mikroarkitektur 0123 movq (r10),r11 X addq $100,r11 X movq r1,(r10) X addq $1,r10 X Her er kun en enkelt fase, kaldet X for eXecute, da alle instruktioner kan udf\u00f8res p\u00e5 en enkelt clock-periode. Vi har alts\u00e5 den sekventielle model, som den vi forst\u00e5r n\u00e5r vi l\u00e6ser et assembler program; alts\u00e5 f\u00f8rst indl\u00e6ser vi noget fra hukommelsen, derefter ligger vi en v\u00e6di til dette, hvorefter vi skriver det tilbage til hukommelsen. Hvis vi \u00f8nsker at finde denne arkitekturs ydeevne, kan man alts\u00e5 g\u00f8re dette ved at t\u00e6lle antallet af instruktioner.","title":"Ide"},{"location":"afviklingsplot/#pipeline-faser-og-ressourcer","text":"En instruktion gennemg\u00e5r nogle faser n\u00e5r den afvikles. Nogle faser er generiske; nogle afh\u00e6nger af instruktionen. Faserne genneml\u00f8bes i r\u00e6kkef\u00f8lge bestemt af instruktionstype og mikroarkitektur. Betragt for eksempel en afviklingen p\u00e5 en simpel pipeline, typisk for de f\u00f8rste RISC maskiner konstrueret i 80'erne. Her er der fem faser: FDXMW (Fetch, Decode, eXecute, Memory, Writeback). Alle instruktioner passerer gennem de samme fem trin. Her ses nogle begr\u00e6nsninger for en 5-trins pipeline: alle instruktioner: FDXMW ressourcer: F:1, D:1, X:1, M:1, W:1 Bem\u00e6rk at det er en voldsom forenkling at udtrykke begr\u00e6nsningen for instruktionshentning i et antal instruktioner. For en maskine med instruktioner af forskellig l\u00e6ngde er bindingen mere korrekt udtrykt som et antal bytes. F\u00f8rst i forbindelse med afkodning er det klart, hvor en instruktion begynder og slutter. Den lille detalje vil vi se bortfra. Her er et afviklingsplot: 01234567 movq (r10),r11 FDXMW addq $100,r12 FDXMW movq r13,(r10) FDXMW addq $1,r10 FDXMW Men hov! Hvorfor kunne det ikke v\u00e6re: 01234567 movq (r10),r11 FDXMW addq $100,r12 FDXMW movq r13,(r10) FDXMW addq $8,r10 FDXMW Vi har m\u00e5ske lidt sv\u00e6rt ved at se, hvordan en maskine overhovedet skulle kunne konstrueres s\u00e5ledes at ovenst\u00e5ende afviklingsr\u00e6kkef\u00f8lge kunne finde sted. Vi indf\u00f8rer derfor en begr\u00e6nsning mere: Hver fase gennemf\u00f8res i instruktions-r\u00e6kkef\u00f8lge. inorder(F,D,X,M,W)","title":"Pipeline faser og ressourcer"},{"location":"afviklingsplot/#data-afhngigheder","text":"Instruktioner bruger en eller flere clock-perioder til at producere et resultat. Det kaldes instruktionens latenstid. Latenstiden er den tid der g\u00e5r fra instruktionen modtager/fremfinder sin sidste indg\u00e5ende operand og til en efterf\u00f8lgende instruktion som afh\u00e6nger af resultatet kan begynde sin beregning. Man planl\u00e6gger normalt en mikroarkitektur s\u00e5ledes at de grundl\u00e6ggende aritmetisk og logiske instruktioner har en latenstid p\u00e5 en enkelt clock periode. Andre instruktioner kan s\u00e5 f\u00e5 l\u00e6ngere latenstid, fordi de udf\u00f8rer et mere kompliceret stykke arbejde. For eksempel er multiplikation mere kompliceret end addition og har derfor en latenstid p\u00e5 3-4 clock perioder. Tilgang til lageret er ogs\u00e5 mere kompliceret og tager l\u00e6ngere tid end en enkelt clock periode. Ex: 5-trins pipeline, data forwarding alle instruktioner: FDXMW dataafh\u00e6ngigheder: simpel aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 multiplikation a op b: X.time = max(a.time, b.time); b.time = X.time + 4 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 1 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 1 inorder(F,D,X,M,W) resourcer pr clk: F:1, D:1, X:1, M:1, W:1 Giver f\u00f8lgende afvikling: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDXMW X.time = r11.time - Forsinket X, STALL i D, r11.time = 5 movq r11,(r10) FFDXMW resA - Forsinket D, STALL i F, X.time = r10.time, S.time = r11.time addq $8,r10 FDXMW resA - forsinket F, r10.time = 7 Bem\u00e6rk hvorledes instruktion nr. 2 bliver forsinket en clock periode i sin D-fase, fordi den afh\u00e6nger af r11 som bliver produceret af den forudg\u00e5ende instruktion der har en latenstid p\u00e5 2 clock-perioder.","title":"Data afh\u00e6ngigheder"},{"location":"afviklingsplot/#superskalar-mikroarkitektur","text":"I jagten efter h\u00f8jere ydeevne kan man finde p\u00e5 at skrue op for ressourcerne. Hvis der er mere end en instruktion der udf\u00f8rer sin X-fase samtidigt, taler man om en superskalar maskine. En simpel 2-vejs superskalar kan h\u00e5ndtere 2 instruktioner samtidigt i faserne F,D,X og W, men kun 1 instruktion samtidigt i fase M. Det er motiveret af at fase M er dyrere end de andre. Til geng\u00e6ld vil man knytte forskellige faser til forskellige klasser af instruktioner, s\u00e5ledes at ikke alle har en fase M. Man kan ogs\u00e5 undg\u00e5 en fase W for instruktioner der ikke skriver til et resultat register simpel aritmetik: FDXW movq (a),b: FDXMW movq b,(a): FDXM dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 1 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 1 inorder(F,D,X,M,W) resourcer pr clk: F:2, D:2, X:2, M:1, W:2 Giver os f\u00f8lgende afvikling: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDDXW X.time = r11.time - Forsinket X, Gentag D, r11.time = 5 movq r11,(r10) FDDXM resB - Forsinket D, Gentag F, X.time = r10.time, M.time = r11.time addq $8,r10 FFFDXW resB - Gentag F, r10.time = 7","title":"Superskalar mikroarkitektur"},{"location":"afviklingsplot/#anonyme-faser","text":"Det er lidt tr\u00e6ls, hvis man skal redeg\u00f8re separat for hver enkelt fase en instruktion genneml\u00f8ber i en moderne mikroarkitektur. Det skyldes at moderne mikroarkitekturer afvikler instruktioner i mange forskellige faser.","title":"Anonyme faser"},{"location":"afviklingsplot/#lngere-pipelines","text":"I moderne CMOS er det ikke realistisk at lave et cache-opslag p\u00e5 en enkelt cyklus. Typisk bruges tre cykler, fuldt pipelinet. Oftest er det heller ikke muligt at fuldt afkode en instruktion p\u00e5 en enkelt cyklus. Vi kunne navngive hver enkelt af de ekstra faser der kr\u00e6ves og opskrive regler for hver af dem. Vi v\u00e6lger en simplere notation: N\u00e5r vi opskriver faserne for en instruktionsklasse kan vi tilf\u00f8je anonyme faser som er p\u00e5kr\u00e6vet med \"-\" og angive hvor mange instuktioner der kan befinde sig i \"mellemrummet\" mellem to navngivne faser. Man kan v\u00e6lge at betragte tidligere beskrivelser af begr\u00e6nsinger som specialtilf\u00e6lde, hvor ingen instruktioner m\u00e5 v\u00e6re i anonyme faser, dvs: F-D: 0, D-X: 0, X-M: 0, M-W: 0. Her betyder s\u00e5leds \"F-D: 0\" at der ingen instruktioner m\u00e5 v\u00e6re, som har gennemf\u00f8rt fase F, men ikke p\u00e5begyndt D. Med andre ord: Fase D skal f\u00f8lge direkte efter fase F i afviklingsplottet For eksempel: resC: max pr clk: F-D: 4, D-X: 2, M-W: 2 Angiver 4 ekstra instruktioner mellem F og D, 2 ekstra mellem D og X og to ekstra mellem M og W. S\u00e5 vi i alt har: aritmetik: F--D-XW movq (a),b: F--D-XM--W movq b,(a): F--D-XM dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 3 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 3 inorder(F,D,X,M,W) resB: max pr clk: F:2, D:2, X:2, M:1, W:2 resC: max pr clk: F-D: 4, D-X: 2, M-W: 2 Hvilket giver f\u00f8lgende afvikling 012345678901234567 movq (r10),r11 F--D-XM--W r11.time = 9 addq $100,r11 F--D-----XW X.time = r11.time - Forsinket X, r11.time = 10 movq r11,(r10) F--D----XM X.time = r10.time, M.time = r11.time addq $8,r10 F--DDDDD-XW r10.time = 11 movq (r10),r11 F--DDDD--XM--W X.time = r10.time, r11.time = 15 addq $100,r11 F------D-----XW X.time = r11.time - Forsinket X, r11.time = 16 movq r11,(r10) F-----DD----XM X.time = r10.time, M.time = r11.time addq $8,r10 F------DDDDD-XW r10.time = 17 Vores specifikation kan kr\u00e6ve anonyme faser, f.eks. 2 mellem F og D som ovenfor, men vi kan ogs\u00e5 inds\u00e6tte yderligere anonyme faser i afviklingsplottet for at f\u00e5 afviklingen til at overholde andre begr\u00e6nsninger.","title":"L\u00e6ngere pipelines"},{"location":"afviklingsplot/#abstraktion","text":"Anonyme faser g\u00f8r det nemmere at se bort fra ting der ikke har interesse. For eksempel kan vi udelade afkodningstrinnet fra vores beskrivelse, men f\u00e5 samme afvikling: aritmetik: F----XW movq (a),b: F----XM--W movq b,(a): F----XM dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: X.time = a.time; M.time = MEM[a].time; b.time = M.time + 3 movq b,(a): X.time = a.time, M.time = b.time; MEM[a].time = S.time + 3 inorder(F,X,M,W) resB: max pr clk: F:2, X:2, M:1, W:2 resC: max pr clk: F-X: 8, M-W: 2 Hvilket giver den samme afvikling, blot er 'D' ikke n\u00e6vnt. 012345678901234567 movq (r10),r11 F----XM--W r11.time = 9 addq $100,r11 F--------XW X.time = r11.time - Forsinket X, r11.time = 10 movq r11,(r10) F-------XM X.time = r10.time, M.time = r11.time addq $8,r10 F--------XW r10.time = 11 movq (r10),r11 F--------XM--W X.time = r10.time, r11.time = 15 addq $100,r11 F------------XW X.time = r11.time - Forsinket X, r11.time = 16 movq r11,(r10) F-----------XM X.time = r10.time, M.time = r11.time addq $8,r10 F------------XW r10.time = 17 Bem\u00e6rk i\u00f8vrigt at selvom denne maskine kan h\u00e5ndtere 2 instruktioner per clk, s\u00e5 opn\u00e5r den i ovenst\u00e5ende eksempel 8/11 IPC, dvs mindre end 1 instruktion per clk.","title":"Abstraktion"},{"location":"afviklingsplot/#ker","text":"TBD","title":"K\u00f8er"},{"location":"afviklingsplot/#cache-miss","text":"TBD","title":"Cache-miss"},{"location":"afviklingsplot/#out-of-order","text":"","title":"Out-of-order"},{"location":"afviklingsplot/#faser-i-program-rkkeflge-eller-ej","text":"Man kunne jo forestille sig: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDDXW X.time = r11.time - Forsinket X, Gentag D, r11.time = 5 movq r9,(r14) FDXM X.time = r14.time, M.time = r9.time ---- BEM\u00c6RK! addq $1,r10 FFDXXW resB - Gentag F, r10.time = 5 (eller 6) Bem\u00e6rk at instruktion nummer 3 her f\u00e5r sin X-fase en clock periode tidligere end instruktionen f\u00f8r. P\u00e5 en m\u00e5de overhaler instruktion nummer 3 alts\u00e5 instruktion nummer 2. Men det tillader vores inorder() erkl\u00e6ring ikke og giver os i stedet: 012345678 movq (r10),r11 FDXMW r11.time = 4 addq $100,r11 FDDDXW X.time = r11.time - Forsinket X, Gentag D, r11.time = 5 movq r9,(r14) FDDXM inorder(X) - Forsinket X, vent i D, X.time = r14.time, M.time = r9.time addq $1,r10 FFFDXW resB - Gentag F, r10.time = 7 Vi kan ane at der findes mere ydeevne i form af mere parallelisme i udf\u00f8relsen, hvis vi blot kan afvige fra inorder-kravet i en eller flere faser. Det har man gjort for \"special cases\" i mange maskiner gennem \u00e5rene, men de sidste 20 \u00e5r er der etableret en mere generel \"standard model\" for out-of-order maskiner","title":"Faser i program-r\u00e6kkef\u00f8lge - eller ej"},{"location":"afviklingsplot/#standardmodellen-for-out-of-order-mikroarkitektur","text":"","title":"Standardmodellen for out-of-order mikroarkitektur"},{"location":"afviklingsplot/#inorder-og-out-of-order","text":"I denne model passerer instruktioner f\u00f8rst i programr\u00e6kkef\u00f8lge gennem en pipeline hvor de ender i en skeduleringsenhed (scheduler). Derfra kan de udf\u00f8res uden at overholde programr\u00e6kkef\u00f8lgen. Efter udf\u00f8rsel placeres resultaterne i en form for k\u00f8. Resultaterne udtages fra denne k\u00f8 og fuldf\u00f8res i programr\u00e6kkef\u00f8lge. Det g\u00e6lder s\u00e5vel for skrivninger til registre, som for skrivninger til lageret. Vi kan beskrive det ved f\u00f8lgende faser der er f\u00e6lles for alle instruktioner: F: Start p\u00e5 instruktionshentning Q: Ankomst til scheduler * C: Fuldf\u00f8relse Og vi benytter lejligheden til at fjerne W trinnet fra beskrivelsen.","title":"Inorder og out-of-order"},{"location":"afviklingsplot/#lagerreferencer","text":"I de hidtil beskrevne maskiner bruger b\u00e5de lagerreferencer og aritmetiske instruktioner fasen X . Det afspejler at man i simple maskiner foretager adresseberegning med den samme hardware som man bruger til aritmetiske instruktioner. I standardmodellen har man i stedet en dedikeret fase til adresseberegning, kaldet A . Denne skelnen mellem A og X g\u00f8r at man kan begr\u00e6nse A til at forekomme i instruktionsr\u00e6kkef\u00f8lge, mens de andre beregninger ikke har den begr\u00e6nsning. Instruktioner der skriver til lageret har et v\u00e6sentlig mere kompliceret forl\u00f8b i en out-of-order maskine sammenlignet med en inorder maskine. Disse instruktioner m\u00e5 ikke opdatere lageret f\u00f8r C , s\u00e5 i stedet placeres skrivningerne i en skrive-k\u00f8. Skrive-k\u00f8en indeholder adresse og data som kan bruges til at udf\u00f8re skrivningen senere, efter C . Instruktioner indf\u00f8jes i skrivek\u00f8en umiddelbart efter A . Da A er en fase der udf\u00f8res i instruktionsr\u00e6kkef\u00f8lge, kan efterf\u00f8lgende instruktioner der l\u00e6ser fra lageret sammenligne deres adresse med udest\u00e5ende skrivninger i skrive-k\u00f8en, og hvis adressen matcher kan den tilsvarende v\u00e6rdi hentes fra skrive-k\u00f8en. Instruktioner der skriver til lageret kan (skal) inds\u00e6tte deres adresse i skrive-k\u00f8en selvom den v\u00e6rdi der skal skrives endnu ikke er beregnet. Det tidspunkt hvor v\u00e6rdien kopieres til skrive-k\u00f8en markeres V .","title":"Lagerreferencer"},{"location":"afviklingsplot/#en-lille-out-of-order-model","text":"Her er en model af en lille out-of-order maskine aritmetik: F----QXC movq (a),b: F----QAM--C movq b,(a): F----QAMVC dataafh\u00e6ngigheder: aritmetik a op b: X.time = max(a.time, b.time); b.time = X.time + 1 movq (a),b: A.time = a.time; M.time = MEM[a].time; b.time = M.time + 3 movq b,(a): A.time = a.time, V.time = b.time; MEM[a].time = V.time + 1 inorder(F,Q,C,A) outoforder(X,M) resB: max pr clk: F:2, Q:2, X:2, A:1, M:1, V:1, C:2 resC: max pr clk: F-Q: 8, M-W: 2, Q-C: 32 resD: unbounded: Q-X, Q-A, A-M, M-V, V-C, M-C Bem\u00e6rk at udover at faserne X og M nu er erkl\u00e6ret out-of-order, s\u00e5 er der indsat en begr\u00e6nsning p\u00e5 32 instruktioner fra Q til C. Det vil sige vi tillader 32 instruktioner at v\u00e6re i forskellige faser mellem Q og C. Dette kaldes skeduleringsvinduet. Jo st\u00f8rre det er, jo flere instruktioner kan maskinen \"se fremad\" i instruktionsstr\u00f8mmen. Bem\u00e6rk ogs\u00e5 at til forskel fra alle de tidligere maskiner er der ikke l\u00e6ngere noget krav om X skal f\u00f8lge i en bestemt afstand efter Q, eller at C skal f\u00f8lge i en bestemt afstand efter X eller M. Disse begr\u00e6nsninger ville give f\u00f8lgende udf\u00f8relse 012345678901234567 movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 movq (r10),r11 F----QAM---C X.time = r10.time, r11.time = 12 addq $100,r11 F----Q----XC X.time = r11.time, r11.time = 13 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 10 Med en gennemsnitlig ydeevne p\u00e5 2 IPC.","title":"En lille out-of-order model"},{"location":"afviklingsplot/#kontrol-afhngigheder","text":"","title":"Kontrol afh\u00e6ngigheder"},{"location":"afviklingsplot/#modellering","text":"Vi modellerer effekten af hop, kald og retur ved at forsinke 'F'. For kald og retur skelner vi mellem korrekte og fejlagtige forudsigelser. For betingede hop skelner vi tillige mellem om hoppet tages eller ej. Vi udtrykker effekten ved tildelinger til en ny tidsvariabel: NextF.time Og for enhver instruktion g\u00e6lder altid at F.time = NextF.time Vi tilf\u00f8jer en ny fase, B , specifik for betingede hop, kald og retur. B svarer til X for de aritmetiske instruktioner. B angiver det tidspunkt, hvor vi afg\u00f8r om forudsigelser af instruktionen var korrekt eller ej. Vi tillader at B indtr\u00e6ffer out-of-order i forhold til andre typer instruktioner, men kr\u00e6ver det sker in-order i forhold til andre hop, kald eller retur. call a,b: F----QBC ret a: F----QBC cbcc a,b,x: F----QBC inorder(B) Her er nogle mulige regler for en out-of-order maskine som beskrevet ovenfor Instruktion Taget Forudsagt Effekt Call ja ja NextF.time = F.time + 2 Ret ja ja NextF.time = F.time + 2 ja nej NextF.time = B.time + 1 CBcc nej ja - (ingen) nej nej NextF.time = B.time + 1 ja ja NextF.time = F.time + 2 ja nej NextF.time = F.time + 2 Herunder ses to genneml\u00f8b af en indre l\u00f8kke, hvor hop forudsiges korrekt. 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbl r10,r12,loop F----QB----C NextF.time = 4 (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C r11.time = 14 addq $100,r11 F----Q----XC r11.time = 15 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 12 cbl r10,r12,loop F----QB----C Ydeevne: 5/4 IPC P\u00e5 grund af omkostningen ved hop vil en overs\u00e6tter ofte rulle en l\u00f8kke-krop ud en eller flere gange. Herunder ses effekten af en enkelt udrulning 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbgt r10,r12,exit F----QB----C forudsagt korrekt ikke taget movq (r10),r11 F----QAM---C r11.time = 13 addq $100,r11 F----Q----XC r11.time = 14 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 11 cbl r10,r12,loop F----QB----C NextF.time = 6 (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C r11.time = 16 Ydeevne: 10/6 IPC En anden teknik til at skjule omkostningen ved tagne hop er at man dimensionerer forenden af mikroarkitektur (F til Q) lidt st\u00f8rre end resten. Her er for eksempel et afviklingsplot for den ikke udrullede l\u00f8kke p\u00e5 en maskine der kan h\u00e5ndtere 3 instruktioner samtidigt i F til Q: 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----Q-AM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbl r10,r12,loop F----Q-B----C NextF.time = 3 (forudsagt korrekt taget) loop: movq (r10),r11 F----QAM--C r11.time = 14 addq $100,r11 F----Q----XC r11.time = 15 movq r11,(r10) F----Q-AM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 12 cbl r10,r12,loop F----Q-B----C Ydeevne: 5/3 IPC Her ses effekten af en forkert forudsigelse: 012345678901234567 loop: movq (r10),r11 F----QAM--C r11.time = 10 addq $100,r11 F----Q----XC r11.time = 11 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 8 cbl r10,r12,loop F----QB----C NextF.time = 9 (forudsagt forkert) loop: movq (r10),r11 F----QAM--C r11.time = 14 addq $100,r11 F----Q----XC r11.time = 15 movq r11,(r10) F----QAM--VC X.time = r10.time, V.time = r11.time addq $8,r10 F----QX----C r10.time = 12 Ydeevne 5/9 IPC Jo l\u00e6ngere pipeline, jo st\u00f8rre omkostning ved forkerte forudsigelser.","title":"Modellering"},{"location":"afviklingsplot/#spekulativ-udfrelse","text":"Det kan ske at B fasen indtr\u00e6ffer meget sent i forhold til udf\u00f8relsen af andre instruktioner. Betragt for eksempel nedenst\u00e5ende stump kode long v = tab[j]; if (v key) { *ptr = *ptr + 1; // found it! } Oversat til x86prime kan det blive til f\u00f8lgende programstump: movq (r10,r11,8),r12 cble r12,r13,.endif movq (r15),r14 addq $1,r14 movq r14,(r15) .endif: og lad os antage at variablen 'tab' befinder sig i L2-cache, mens omr\u00e5det udpeget af variablen 'ptr' er i L1-cache. Lad os antage at L2-cache tilgang koster 10 cykler (oveni L1-tilgang). 01234567890123456789012 movq (r10,r11,8),r12 F----QAM------------C cble r12,r13,else F----Q--------------BC movq (r15),r14 F----QAM------------C addq $1,r14 F----Q----X----------C movq r14,(r15) F----QAM--V---------C Det betingede hop afh\u00e6nger af en instruktion der er n\u00f8d til at hente en v\u00e6rdi i L2 og bliver s\u00e5ledes forsinket s\u00e5 det f\u00f8rst kan afg\u00f8res i cyklus 20. Hoppet er forudsagt \"ikke taget\" og f\u00f8r det afg\u00f8res kan de n\u00e6ste tre instruktioner l\u00e6se fra L1-cachen, beregne en ny v\u00e6rdi og l\u00e6gge den i k\u00f8 til skrivning til L1. Det g\u00e5r selvsagt ikke an faktisk at opdatere L1, f\u00f8r vi ved om hoppet er forudsagt korrekt, men alle \u00f8vrige aktiviteter kan gennemf\u00f8res. De instruktioner som udf\u00f8res tidligere end et eller flere hop, kald eller retur, som de egentlig afh\u00e6nger af, siges at v\u00e6re spekulativt udf\u00f8rt. Spekulativ udf\u00f8relse fjerner en v\u00e6sentlig begr\u00e6nsning p\u00e5 hvor meget arbejde der kan udf\u00f8res parallelt.","title":"spekulativ udf\u00f8relse"}]}